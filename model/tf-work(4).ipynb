{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# import tensorflow as tf\n",
    "# if tf.test.gpu_device_name():\n",
    "#     print('GPU found')\n",
    "# else:\n",
    "#     print(\"No GPU found\")\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-26T14:30:45.901808Z",
     "iopub.execute_input": "2022-03-26T14:30:45.902742Z",
     "iopub.status.idle": "2022-03-26T14:30:45.931046Z",
     "shell.execute_reply.started": "2022-03-26T14:30:45.902612Z",
     "shell.execute_reply": "2022-03-26T14:30:45.930244Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def colab_download(proj_name,is_kaggle):\n",
    "    import requests\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    if is_kaggle:\n",
    "        import sys\n",
    "        sys.path.append(\"/kaggle/working/\")\n",
    "\n",
    "    project_name=proj_name\n",
    "\n",
    "    url = f'http://kuroweb.tk:8000/api/v1/pack/wyftp/dataset/{project_name}.tar.gz'\n",
    "    user, password = 'wuying', '123aaa'\n",
    "    response = requests.get(url, stream=True,auth=(user, password))\n",
    "    total_size_in_bytes= int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024 #1 Kibibyte\n",
    "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "    with open('download.tar.gz', 'wb') as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "    progress_bar.close()\n",
    "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "        print(\"ERROR, something went wrong\")\n",
    "\n",
    "    import tarfile\n",
    "\n",
    "    # open file\n",
    "    file = tarfile.open('download.tar.gz')\n",
    "    # extracting file\n",
    "    file.extractall('./')\n",
    "    file.close()\n",
    "\n",
    "    import shutil\n",
    "    import os\n",
    "\n",
    "    source_dir = f'./{project_name}'\n",
    "    target_dir = './'\n",
    "\n",
    "    file_names = os.listdir(source_dir)\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            shutil.move(os.path.join(source_dir, file_name), target_dir)\n",
    "        except Exception as e:\n",
    "            print(e,'at',file_name)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:30:45.932549Z",
     "iopub.execute_input": "2022-03-26T14:30:45.932961Z",
     "iopub.status.idle": "2022-03-26T14:30:45.941619Z",
     "shell.execute_reply.started": "2022-03-26T14:30:45.932929Z",
     "shell.execute_reply": "2022-03-26T14:30:45.941038Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "colab_download('model',True)\n",
    "!pip install -r requirements.txt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:30:45.943177Z",
     "iopub.execute_input": "2022-03-26T14:30:45.943593Z",
     "iopub.status.idle": "2022-03-26T14:33:43.518052Z",
     "shell.execute_reply.started": "2022-03-26T14:30:45.943563Z",
     "shell.execute_reply": "2022-03-26T14:33:43.515861Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# record start time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.core.display import display\n",
    "from keras import layers\n",
    "# residual block\n",
    "# https://stackoverflow.com/questions/64792460/how-to-code-a-residual-block-using-two-layers-of-a-basic-cnn-algorithm-built-wit\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from general_model.grow_numpy import GrowableNumpyArray\n",
    "from general_model.list_batch_loader import ListBatchLoadDataset\n",
    "from model_helper.single_gpu_dataloader import SingleGpuTensorWrapper\n",
    "from pytorch_regression.regression_params import RegressionParams\n",
    "from tool import ml, wine_tool, data_loader, wine_data_loader\n",
    "from tool.dbg import dbg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:33:43.525340Z",
     "iopub.execute_input": "2022-03-26T14:33:43.525766Z",
     "iopub.status.idle": "2022-03-26T14:33:51.649996Z",
     "shell.execute_reply.started": "2022-03-26T14:33:43.525709Z",
     "shell.execute_reply": "2022-03-26T14:33:51.649183Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:33:51.651364Z",
     "iopub.execute_input": "2022-03-26T14:33:51.651605Z",
     "iopub.status.idle": "2022-03-26T14:33:51.673303Z",
     "shell.execute_reply.started": "2022-03-26T14:33:51.651575Z",
     "shell.execute_reply": "2022-03-26T14:33:51.672715Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wine_json = ml.read_json(\"Wine.json\")\n",
    "\n",
    "\n",
    "class RegressionTrainer:\n",
    "    def __init__(self):\n",
    "        self.param = RegressionParams()\n",
    "        self.param.batch_size = 64\n",
    "        self.param.epoch = 1\n",
    "        self.param.lr = 1e-9\n",
    "        self.param.cnn_stride = 1\n",
    "        self.param.cnn_size = 3\n",
    "        self.param.pool_size = 2\n",
    "        self.param.lr_decay = 0.99\n",
    "\n",
    "    def load(self):\n",
    "\n",
    "        self.x = GrowableNumpyArray(dtype=np.float, grow_speed=16)\n",
    "        self.y = GrowableNumpyArray(dtype=np.float, grow_speed=16)\n",
    "\n",
    "        for wine in wine_json:\n",
    "            base_wine_path = 'data4/' + wine['id']\n",
    "            dbg(wine['name'])\n",
    "            if not os.path.exists(base_wine_path):\n",
    "                dbg('not exists:', base_wine_path)\n",
    "                continue\n",
    "            # load data\n",
    "            dirs = ml.getAllFiles(f'{base_wine_path}')\n",
    "            for d in dirs:\n",
    "                path = d\n",
    "                files = ml.getAllFileRecursively(path)\n",
    "                for f in files:\n",
    "                    self.x.update(wine_tool.col2data_to_float_list(f))\n",
    "                    self.y.add(wine['degree'])\n",
    "                    # self.x = np.append(self.x, wine_tool.col2data_to_float_list(f))\n",
    "                    # self.y = np.append(self.y, wine['degree'])\n",
    "\n",
    "            # load item_data\n",
    "            for wine_item in wine['items']:\n",
    "                sub_wine_path = base_wine_path + '_' + wine_item['name']\n",
    "\n",
    "                dirs = ml.getAllFiles(f'{sub_wine_path}')\n",
    "                dbg(wine_item)\n",
    "                for d in dirs:\n",
    "                    path = d\n",
    "                    files = ml.getAllFileRecursively(path)\n",
    "                    for f in files[:100]:\n",
    "                        self.x.update(wine_tool.col2data_to_float_list(f))\n",
    "                        self.y.add(wine_item['degree'])\n",
    "                        # self.x = np.append(self.x, wine_tool.col2data_to_float_list(f))\n",
    "                        # self.y = np.append(self.y, wine_item['degree'])\n",
    "\n",
    "        self.x = self.x.finalize()\n",
    "        self.x = self.x.reshape((-1, 1000))\n",
    "\n",
    "        self.y = self.y.finalize()\n",
    "\n",
    "        plt.plot(sorted(self.y))\n",
    "        plt.plot(self.y)\n",
    "\n",
    "        # normalize\n",
    "\n",
    "        self.y = self.y / 100\n",
    "\n",
    "        layer_normed_x = torch.nn.LayerNorm([1000])(torch.tensor(self.x, dtype=torch.float))\n",
    "        i = 0\n",
    "        while i < 3:\n",
    "            indice = i\n",
    "            plt.plot(layer_normed_x[indice].detach().numpy(), label=self.y[indice])\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            i += 1\n",
    "\n",
    "        self.x, self.y, self.x1, self.y1 = wine_data_loader.split(self.x, self.y, 1 - self.param.train_test_split)\n",
    "\n",
    "        # wine_dataset = ListBatchLoadDataset(self.x.tensor, self.y.tensor)\n",
    "        # self.dataloader = DataLoader(wine_dataset, batch_size=self.param.batch_size,\n",
    "        #                         shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "trainer = RegressionTrainer()\n",
    "trainer.load()\n",
    "dbg(trainer.x.shape, trainer.y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:33:51.675836Z",
     "iopub.execute_input": "2022-03-26T14:33:51.676187Z",
     "iopub.status.idle": "2022-03-26T14:33:59.790182Z",
     "shell.execute_reply.started": "2022-03-26T14:33:51.676157Z",
     "shell.execute_reply": "2022-03-26T14:33:59.789176Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:33:59.791488Z",
     "iopub.execute_input": "2022-03-26T14:33:59.792556Z",
     "iopub.status.idle": "2022-03-26T14:33:59.796598Z",
     "shell.execute_reply.started": "2022-03-26T14:33:59.792518Z",
     "shell.execute_reply": "2022-03-26T14:33:59.795707Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "多层Dense模型"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# act = 'tanh'\n",
    "# # inp = __next = layers.Input(shape=[1280 * 720*10], name='input')\n",
    "# inp = __next = layers.Input(shape=[1000], name='input')\n",
    "# __next = layers.Dense(4000, activation=act)(__next)\n",
    "# # __next = layers.Dense(800, activation=act)(__next)\n",
    "# # __next = layers.Dense(800, activation=act)(__next)\n",
    "# __next = layers.Dense(100, activation=act)(__next)\n",
    "# __next = layers.Dense(10, activation=act)(__next)\n",
    "# output = __next = layers.Dense(1, )(__next)\n",
    "# model = keras.Model(inputs=[inp], outputs=[output])\n",
    "# model.summary()\n",
    "# # opt = tf.keras.optimizers.Adam(lr=1e-4)\n",
    "# opt = tf.keras.optimizers.Adam(lr=1e-6)\n",
    "# model.compile(\n",
    "#     optimizer=opt,\n",
    "#     # optimizer='adam',\n",
    "#     loss='mse',\n",
    "# )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-26T14:33:59.798022Z",
     "iopub.execute_input": "2022-03-26T14:33:59.798221Z",
     "iopub.status.idle": "2022-03-26T14:33:59.813102Z",
     "shell.execute_reply.started": "2022-03-26T14:33:59.798196Z",
     "shell.execute_reply": "2022-03-26T14:33:59.812029Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "kernel_count=3\n",
    "act = 'tanh'\n",
    "# inp = __next = layers.Input(shape=[1280 * 720*10], name='input')\n",
    "inp = __next = layers.Input(shape=[1000], name='input')\n",
    "__next = layers.Reshape(target_shape=[1000, 1], name='reshape')(__next)\n",
    "\n",
    "for i in range(3):\n",
    "    res=__next\n",
    "    v1 = layers.Conv1D(filters=kernel_count, kernel_size=3,padding='same',activation=act)(res)\n",
    "    v2 = layers.Conv1D(filters=kernel_count, kernel_size=5,padding='same',activation=act)(res)\n",
    "    v3 = layers.Conv1D(filters=kernel_count, kernel_size=7,padding='same',activation=act)(res)\n",
    "    v4 = layers.Conv1D(filters=kernel_count, kernel_size=9,padding='same',activation=act)(res)\n",
    "    v5 = layers.Conv1D(filters=kernel_count, kernel_size=1,padding='same',activation=act)(res)\n",
    "    \n",
    "    __next=layers.Concatenate(axis=2)([v1,v2,v3,v4,v5])\n",
    "    if i!=0:\n",
    "        __next=res+__next\n",
    "__next=layers.AvgPool1D(pool_size=50,strides=50)(__next)\n",
    "__next = layers.Flatten()(__next)\n",
    "__next = layers.Dense(10, activation=act)(__next)\n",
    "output = __next = layers.Dense(1, )(__next)\n",
    "model = keras.Model(inputs=[inp], outputs=[output])\n",
    "model.summary()\n",
    "# opt = tf.keras.optimizers.Adam(lr=1e-4)\n",
    "opt = tf.keras.optimizers.Adam(lr=1e-6)\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    # optimizer='adam',\n",
    "    loss='mse',\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:33:59.814353Z",
     "iopub.execute_input": "2022-03-26T14:33:59.815231Z",
     "iopub.status.idle": "2022-03-26T14:34:00.470565Z",
     "shell.execute_reply.started": "2022-03-26T14:33:59.815188Z",
     "shell.execute_reply": "2022-03-26T14:34:00.469762Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# # loss:0.0147\n# act = 'tanh'\n# config = [\n#     ('conv', 4, 3),\n#     ('pool', 2),\n#     ('activation',act),\n#     ('conv', 4, 3),\n#     ('pool', 2),\n#     ('activation',act),\n\n#     ('conv', 16, 3),\n#     ('pool', 2),\n#     ('activation',act),\n\n#     (\"conv\", 16, 3),\n#     ('pool', 2),\n#     ('activation',act),\n\n#     (\"conv\", 64, 3),\n#     ('pool', 2),\n#     ('activation',act),\n\n#     (\"conv\", 64, 3),\n#     ('pool', 2),\n    \n    \n#     (\"conv\", 256, 3),\n#     ('pool', 2),\n#     ('activation',act),\n\n#     (\"conv\", 1024, 3),\n#     ('pool', 2),\n#     ('activation',act),\n# ]\n# # inp = __next = layers.Input(shape=[1280 * 720*10], name='input')\n# inp = __next = layers.Input(shape=[1000], name='input')\n# __next = layers.Reshape(target_shape=[1000, 1], name='reshape')(__next)\n\n# for c in config:\n#     if c[0] == 'conv':\n#         __next = layers.Conv1D(filters=c[1], kernel_size=c[2])(__next)\n#     elif c[0] == 'pool':\n#         __next = layers.MaxPool1D(pool_size=c[1])(__next)\n#     elif c[0] == 'activation':\n#         __next = layers.Activation(c[1])(__next)\n\n# __next = layers.Flatten()(__next)\n# output = __next = layers.Dense(1, )(__next)\n# model = keras.Model(inputs=[inp], outputs=[output])\n# model.summary()\n# # opt = tf.keras.optimizers.Adam(lr=1e-4)\n# opt = tf.keras.optimizers.Adam(lr=1e-4)\n# model.compile(\n#     optimizer=opt,\n#     # optimizer='adam',\n#     loss='mse',\n# )",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:34:00.472776Z",
     "iopub.execute_input": "2022-03-26T14:34:00.473086Z",
     "iopub.status.idle": "2022-03-26T14:34:00.482919Z",
     "shell.execute_reply.started": "2022-03-26T14:34:00.473055Z",
     "shell.execute_reply": "2022-03-26T14:34:00.479004Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class CustomCallback(keras.callbacks.Callback):\n    def __init__(self):\n        self.val_fit=[]\n        \n    def on_epoch_begin(self, epoch, logs=None):\n#         keys = list(logs.keys())\n#         print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n        pass\n    def on_epoch_end(self, epoch, logs=None):\n#         keys = list(logs.keys())\n#         print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n        \n        prediction = self.model.predict(trainer.x1)\n        dif = prediction.reshape(-1, ) - trainer.y1\n        percent=np.sum((np.abs(dif) < 0.025)) / len(dif) * 100\n        self.val_fit.append(percent)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-26T14:34:00.484260Z",
     "iopub.execute_input": "2022-03-26T14:34:00.484487Z",
     "iopub.status.idle": "2022-03-26T14:34:00.500802Z",
     "shell.execute_reply.started": "2022-03-26T14:34:00.484460Z",
     "shell.execute_reply": "2022-03-26T14:34:00.499907Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "callback_for_percent=CustomCallback()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-26T14:34:00.501774Z",
     "iopub.execute_input": "2022-03-26T14:34:00.502025Z",
     "iopub.status.idle": "2022-03-26T14:34:00.515540Z",
     "shell.execute_reply.started": "2022-03-26T14:34:00.501990Z",
     "shell.execute_reply": "2022-03-26T14:34:00.514768Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "history = model.fit(trainer.x, trainer.y,\n                    # validation_data=(X_test, Y_test)\n#                     epochs=50,\n#                     epochs=100,\n#                     epochs=10000,\n#                     epochs=400,\n                    epochs=18000,\n#                     epochs=15000,\n#                     epochs=500,\n                    # epochs=300,\n                    callbacks=[callback_for_percent]\n                    )",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:34:00.517017Z",
     "iopub.execute_input": "2022-03-26T14:34:00.517364Z",
     "iopub.status.idle": "2022-03-26T14:35:28.791880Z",
     "shell.execute_reply.started": "2022-03-26T14:34:00.517305Z",
     "shell.execute_reply": "2022-03-26T14:35:28.790470Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "\npd.DataFrame(callback_for_percent.val_fit).plot(figsize=(8, 5))\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-26T14:35:28.793167Z",
     "iopub.status.idle": "2022-03-26T14:35:28.794045Z",
     "shell.execute_reply.started": "2022-03-26T14:35:28.793803Z",
     "shell.execute_reply": "2022-03-26T14:35:28.793829Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "start_indice=(len(history.history[\"loss\"])//3)\npd.DataFrame(history.history['loss'][start_indice:]).plot(figsize=(8, 5))\n# plt.grid(True)\n# plt.gca().set_ylim(0, 5e-4)\n# plt.gca().set_ylim(0, 0.02)\n\nplt.show()\n\n\nprediction = model.predict(trainer.x1)\ndict = {'predict': prediction[:15, 0],\n        'truth': trainer.y1[:15],\n        'diff': (prediction[:15, 0] - trainer.y1[:15])\n        }\ndf = pd.DataFrame(dict)\n\n# displaying the DataFrame\ndisplay(df.T)\n\n",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:35:28.795163Z",
     "iopub.status.idle": "2022-03-26T14:35:28.795850Z",
     "shell.execute_reply.started": "2022-03-26T14:35:28.795657Z",
     "shell.execute_reply": "2022-03-26T14:35:28.795679Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 输出误差小于2.5度的百分比\ndif = prediction.reshape(-1, ) - trainer.y1\nnp.sum((np.abs(dif) < 0.025)) / len(dif) * 100",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-26T14:35:28.797175Z",
     "iopub.status.idle": "2022-03-26T14:35:28.797806Z",
     "shell.execute_reply.started": "2022-03-26T14:35:28.797526Z",
     "shell.execute_reply": "2022-03-26T14:35:28.797565Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# 调参记录\n\n学习率调高到10的-4次方\n\n训练轮次从500调整的5000，训练了3.2小时\n\n换成mlp Dense模型\n\nver 9 10000 epoch只训练了不到1小时\n\nver 11 9w epoch，结果88%，还行，loss: 4.9452e-08，太低了 300-400 epoch就够了",
   "metadata": {}
  }
 ]
}